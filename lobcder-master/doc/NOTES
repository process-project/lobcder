To clear up files not showing up in ldata_table: update pdrigroup_table set `refCount` = 0 where pdriGroupId not in (select pdriGroupRef from ldata_table where pdriGroupRef != 0)


-------------------------------------------------------------------------------------------------------------------
To install on a new machine (ubuntu 12, debian)
--------------------Set up master-----------------------------------------------
echo "deb http://ppa.launchpad.net/webupd8team/java/ubuntu precise main" | tee -a /etc/apt/sources.list
echo "deb-src http://ppa.launchpad.net/webupd8team/java/ubuntu precise main" | tee -a /etc/apt/sources.list
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys EEA14886
apt-get update
apt-get upgrade

export DEBIAN_FRONTEND=noninteractive
echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections
echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections

apt-get -q -y --force-yes  install mysql-server mysql-client oracle-java7-installer git maven2 erlang wget makepasswd nmap bwm-ng

cd 


wget http://apache.mirror.triple-it.nl/tomcat/tomcat-6/v6.0.43/bin/apache-tomcat-6.0.43.tar.gz
tar -xavf apache-tomcat-6.0.43.tar.gz

wget https://raw.githubusercontent.com/skoulouzis/lobcder/dev/lobcder-master/scripts/deployMaster.sh
chmod +x deployMaster.sh
wget https://github.com/skoulouzis/lobcder/blob/dev/lobcder-master/scripts/storageFile
./deployMaster.sh -n lobcderDB -p pass -u root -a mysqlRootPassword -f storageFile -l lobcderAdmin -s lobcderAdmin -c ./apache-tomcat-6.0.43



git clone https://github.com/skoulouzis/lobcder.git
cd lobcder/lobcder-master
mvn clean install 
rm -r target/lobcder
mv target/lobcder-master-?.?  target/lobcder
#Keep old configuration 
rm target/lobcder/manage* target/lobcder/WEB-INF/classes/workers target/lobcder/WEB-INF/web.xml target/lobcder/META-INF/context.xml target/lobcder/WEB-INF/classes/lobcder.properties
cd /root
cp -r lobcder/lobcder-master/target/lobcder apache-tomcat-*/webapps/
./apache-tomcat-6.0.36/bin/startup.sh

--------------------Set up worker-----------------------------------------------

echo "deb http://ppa.launchpad.net/webupd8team/java/ubuntu precise main" | tee -a /etc/apt/sources.list
echo "deb-src http://ppa.launchpad.net/webupd8team/java/ubuntu precise main" | tee -a /etc/apt/sources.list
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys EEA14886
apt-get update

export DEBIAN_FRONTEND=noninteractive
echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections
echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections
apt-get -q -y --force-yes  install oracle-java7-installer git maven2 erlang wget makepasswd nmap openvpn

password="pass"
pass=$(perl -e 'print crypt($ARGV[0], "password")' $password)
useradd w -m -p $pass


wget http://elab.lab.uvalight.net/~lobcder/apache-tomcat-6.0.36.tar.gz
tar -xzvf apache-tomcat-6.0.36.tar.gz

keytool -genkey -alias tomcat -keyalg RSA 



./apache-tomcat-6.0.36/bin/shutdown.sh
git clone https://github.com/skoulouzis/lobcder.git
cd lobcder/lobcder-worker/
mvn install 
rm -r target/lobcder-worker
mv target/lobcder-worker-?.?-SNAPSHOT target/lobcder-worker
cd /root
cp -r lobcder/lobcder-worker/target/lobcder-worker apache-tomcat-6.0.36/webapps/
./apache-tomcat-6.0.36/bin/startup.sh


sleep 70 
for i in {1..6}; do ping -c 10 192.168.100.$i; done
 apt-get install screen
screen -d -m sh -c "for i in {1..60}; do ping -c 30 192.168.100.$i; done"


for i in {1..7}; do wget http://localhost:8080/lobcder-worker/2/1; ./apache-tomcat-6.0.36/bin/shutdown.sh; ./apache-tomcat-6.0.36/bin/startup.sh;  done


------- set up openvpn with storage --------
https://help.ubuntu.com/lts/serverguide/openvpn.html#openvpn-simple-client-configuration


-------------------------------------------------------------------------------------
to solve the of type default using the available factories WagonRepositoryConnectorFactory 
error when building go to http://elab.lab.uvalight.net/artifactory/webapp/mavensettings.html generate the settings and paste them to ~/m2/settings.xml

---------------------------------------------------------------------------------------
To start events for to sweep short tokens: SET GLOBAL event_scheduler = ON;

----------------------------------------------------------------------------------------
We have to keep two different global_id: one for MR and other for test MR. To do so I add a column to the wp4_table. Now DDL for wp4_table shall be:
CREATE TABLE wp4_table (
 id SERIAL PRIMARY KEY,
 local_id BIGINT UNSIGNED, FOREIGN KEY(local_id) REFERENCES ldata_table(uid) ON DELETE SET NULL ,
 global_id VARCHAR(255),
 global_id_dev VARCHAR(255),
 views INT UNSIGNED NOT NULL DEFAULT 0,
 need_update BOOLEAN NOT NULL DEFAULT FALSE, INDEX(need_update),
 need_create BOOLEAN NOT NULL DEFAULT TRUE, INDEX(need_create)
) ENGINE=InnoDB;

To modify existing table we can use this:

ALTER TABLE wp4_table ADD global_id_dev VARCHAR(255) AFTER global_id;



-----------------------Build state graph from request table--------------------
insert into successor_table (keyVal,lobStateID,weight) 

SELECT 
keyVal, 
lobStateID, 
sum(count) AS weight
FROM (
select 
    rt.uid,
    CONCAT(rt.methodname, ', ', rt.requestUrl) AS keyval,
    rtn.lobStateId,
    rtn.previousuid,
    1 AS count
FROM requests_table AS rt
JOIN
(
select uid, uid-1 AS previousuid, CONCAT(methodname, ', ', requestUrl) AS lobstateId from requests_table AS rt
) AS rtn
ON rt.uid = rtn.previousuid
) AS bla
GROUP BY 
keyval, 
lobstateId
ORDER BY weight DESC;



select count, prob, cumulativeSum(prob) from
(select count, (count(*)/(select count(*) from graph_table)) as prob from graph_table group by count order by count) 
as countProb



select DATE_FORMAT(logdate, '%m/%y'), SUM(repl_size) as time from repl_stats GROUP BY YEAR(logdate), MONTH(logdate);

select SUM(tx_size) as tx_size from tx_stats 
where tx_destination_country_code2 = 'IE';

select count(*) as Num_of_req from  lobStats.req_stats 
where lobStats.req_stats.req_source_country_code2 = 'PL';

---------------------------------------------------------

follow redirects and resume downloads 
curl -u user:pass -C - -O -L http://192.168.100.2:8080/lobcder/dav/file

export ec=18; while [ $ec -eq 18 ]; do curl -O -C - -L --request GET -u user:pass http://192.168.100.2:8080/lobcder/dav/file; export ec=$?; done

------------------generate random file--------------
dd if=/dev/urandom of=file100MB bs=100M count=1

-------------------------Configure openVSwitch with sFlow----------------------
From http://www.areteix.net/blog/2013/08/network-flow-monitoring-with-open-vswitch/
S1: 
COLLECTOR_IP=192.168.2.1
COLLECTOR_PORT=6343
AGENT=eth2
HEADER=128
SAMPLING=256
POLLING=10


ovs-vsctl -- --id=@sflow create sflow agent=${AGENT} target=\"${COLLECTOR_IP}:${COLLECTOR_PORT}\" header=${HEADER} sampling=${SAMPLING} polling=${POLLING} -- set bridge br0 sflow=@sflow

---------------------------Post boot script:----------------------------------

#!/bin/bash

# Wait for interfaces to be configured. This value should be tweaked.
sleep 70

# Create bridge
ovs-vsctl add-br br0

# Figure out which interfaces don't have an IP address and add to the bridge.
if ! ifconfig eth1 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth1; ifconfig eth1 up; else AGENT=eth1; fi
if ! ifconfig eth2 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth2; ifconfig eth2 up; else AGENT=eth2; fi
if ! ifconfig eth3 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth3; ifconfig eth3 up; else AGENT=eth3; fi
if ! ifconfig eth4 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth4; ifconfig eth4 up; else AGENT=eth4; fi

# Configure controller
ovs-vsctl set-controller br0 tcp:192.168.2.1:6633


COLLECTOR_IP=192.168.2.1
COLLECTOR_PORT=6343
HEADER=128
SAMPLING=128
POLLING=5

ovs-vsctl -- --id=@sflow create sflow agent=${AGENT} target=\"${COLLECTOR_IP}:${COLLECTOR_PORT}\" header=${HEADER} sampling=${SAMPLING} polling=${POLLING} -- set bridge br0 sflow=@sflow



---------------------------------------------------------------------------------
#!/bin/bash

# Wait for interfaces to be configured. This value should be tweaked.
sleep 70

# Create bridge
ovs-vsctl add-br br0

# Figure out which interfaces don't have an IP address and add to the bridge.
if ! ifconfig eth1 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth1; ifconfig eth1 up; else AGENT=eth1; fi
if ! ifconfig eth2 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth2; ifconfig eth2 up; else AGENT=eth2; fi
if ! ifconfig eth3 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth3; ifconfig eth3 up; else AGENT=eth3; fi
if ! ifconfig eth4 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth4; ifconfig eth4 up; else AGENT=eth4; fi
if ! ifconfig eth5 | grep -q 'inet addr'; then ovs-vsctl add-port br0 eth5; ifconfig eth5 up; else AGENT=eth5; fi

# Configure controller
ovs-vsctl set-controller br0 tcp:192.168.3.1:6633


COLLECTOR_IP=192.168.3.1
COLLECTOR_PORT=6343
HEADER=128
SAMPLING=128
POLLING=5

ovs-vsctl -- --id=@sflow create sflow agent=${AGENT} target=\"${COLLECTOR_IP}:${COLLECTOR_PORT}\" header=${HEADER} sampling=${SAMPLING} polling=${POLLING} -- set bridge br0 sflow=@sflow

--------------------------------------------------------------------------------------

From http://145.100.133.130:8008/html/api.html
Controller: 
wget http://www.inmon.com/products/sFlow-RT/sflow-rt.tar.gz

tar -xvzf sflow-rt.tar.gz
cd sflow-rt
./start.sh




-----------------------------Controller post boot script------------------------

apt-get -y install default-jdk ant git screen >> /var/log/post-boot.log
git clone git://github.com/floodlight/floodlight.git /opt/floodlight >> /var/log/post-boot.log
cd /opt/floodlight
ant >> /var/log/post-boot.log
screen -d -m sh -c "java -jar /opt/floodlight/target/floodlight.jar"

wget http://www.inmon.com/products/sFlow-RT/sflow-rt.tar.gz

tar -xvzf sflow-rt.tar.gz
cd sflow-rt
screen -d -m sh -c "./start.sh"




--------------------------limit BW--------------------------
tc qdisc add dev $1 root handle 1: htb default 12 
tc class add dev $1 parent 1:1 classid 1:12 htb rate 20kbps ceil 20kbps 
tc qdisc add dev $1 parent 1:12 netem delay 1000ms 


--------------remove limit
tc qdisc del root dev $1



-----------------------------process usage data from elasticsearch
curl "http://elab.lab.uvalight.net/elasticsearch/_all/_search?q=rx_size:*&size=5" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.rx_source)\t\(.rx_destination)\t\(.rx_speed)\t\(.rx_size)\t\(.rx_sourceLoc.country_code2)\t\(.rx_sourceLoc.country_name)"'

curl "http://elab.lab.uvalight.net/elasticsearch/_all/_search?q=tx_size:*&size=5" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.tx_source)\t\(.tx_destination)\t\(.tx_speed)\t\(.tx_size)\t\(.tx_destinationLoc.country_code2)\t\(.tx_destinationLoc.country_name)"'


curl "http://elab.lab.uvalight.net/elasticsearch/_all/_search?q=req_source:*&from=0&size=5" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.req_sourceLoc.country_code2)\t\(.req_sourceLoc.country_name)\t\(.req_sourceLoc.city_name)\t\(.req_userAgent)\t\(.req_user)\t\(.req_verb)\t\(.req_contLen)\t\(.req_contType)\t\(.req_elapsed)\t\(.req_contType)\t\(.req_queryString)\t\(.req_URL)"'


jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.repl_source)\t\(.repl_destination)\t\(.repl_speed)\t\(.repl_size)"'



for((i=0;i<=2000000;i+=1000)); do curl "http://localhost:9200/_all/_search?q=rx_size:*&from=$i&size=1000" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.rx_source)\t\(.rx_destination)\t\(.rx_speed)\t\(.rx_size)\t\(.rx_sourceLoc.country_code2)\t\(.rx_sourceLoc.country_name)"'; done  >> rx_size.csv

for((i=0;i<=2000000;i+=1000)); do curl "http://localhost:9200/_all/_search?q=tx_size:*&from=$i&size=1000" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.tx_source)\t\(.tx_destination)\t\(.tx_speed)\t\(.tx_size)\t\(.tx_destinationLoc.country_code2)\t\(.tx_destinationLoc.country_name)"'; done  >> tx_size.csv

for((i=0;i<=2000000;i+=1000)); do curl "http://localhost:9200/_all/_search?q=req_source:*&from=$i&size=1000" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.req_sourceLoc.country_code2)\t\(.req_sourceLoc.country_name)\t\(.req_sourceLoc.city_name)\t\(.req_userAgent)\t\(.req_user)\t\(.req_verb)\t\(.req_contLen)\t\(.req_contType)\t\(.req_elapsed)\t\(.req_contType)\t\(.req_queryString)\t\(.req_URL)"'; done  >> req_size.csv

for((i=0;i<=2000000;i+=1000)); do curl "http://localhost:9200/_all/_search?q=repl_source:*&from=$i&size=1000" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.repl_source)\t\(.repl_destination)\t\(.repl_speed)\t\(.repl_size)"' && sleep 1; done >> repl_size.csv

for((i=0;i<=2000000;i+=1000)); do curl "http://localhost:9200/_all/_search?q=apache_startupTime:*&from=$i&size=1000" | jq --raw-output '.hits.hits | .[] | ._source | "\(.logdate)\t\(.apache_startupTime)"'; done  >> apache_startupTime.csv


------------------------------------ Import data from csv-----------------------------------------
CREATE TABLE  apache_startupTime (
 logdate DATE,
 apache_startupTime DOUBLE
) ENGINE=InnoDB;

LOAD DATA LOCAL INFILE 'apache_startupTime.csv' 
INTO TABLE apache_startupTime FIELDS TERMINATED BY '\t' 
LINES TERMINATED BY '\n' 
(@var1,apache_startupTime)
set logdate = STR_TO_DATE(@var1, '%M %d,%Y %h:%i:%s %p')



CREATE TABLE  repl_stats (
 logdate DATE,
 repl_source VARCHAR(5240),
 repl_destination VARCHAR(5240),
 repl_speed DOUBLE, 
 repl_SIZE DOUBLE
) ENGINE=InnoDB;


LOAD DATA LOCAL INFILE '/home/alogo/Downloads/repl_size.csv' 
INTO TABLE repl_stats FIELDS TERMINATED BY '\t' 
LINES TERMINATED BY '\n' 
(@var1,repl_source,repl_destination,repl_speed,repl_size)
set logdate = STR_TO_DATE(@var1, '%M %d,%Y %h:%i:%s %p')



CREATE TABLE  req_stats (
 logdate DATE,
 req_source_country_code2 VARCHAR(5240),
 req_source_country_name VARCHAR(5240),
 req_source_city_name VARCHAR(5240),
 req_userAgent VARCHAR(5240),
 req_user VARCHAR(5240),
 req_verb VARCHAR(5240),
 req_contLen BIGINT,
 req_contType VARCHAR(5240),
 req_elapsed DOUBLE, 
 req_contType1 VARCHAR(5240),
 req_queryString VARCHAR(5240),
 req_URL VARCHAR(5240)
) ENGINE=InnoDB;

LOAD DATA LOCAL INFILE '/home/alogo/Downloads/req_size.csv' 
INTO TABLE req_stats FIELDS TERMINATED BY '\t' 
LINES TERMINATED BY '\n' 
(@var1,req_source_country_code2,req_source_country_name,req_source_city_name,req_userAgent,req_user,req_verb,req_contLen,req_contType,
req_elapsed,req_contType1,req_queryString,req_URL)
set logdate = STR_TO_DATE(@var1, '%M %d,%Y %h:%i:%s %p')




LOAD DATA LOCAL INFILE '/home/alogo/Downloads/tx_size.csv' 
INTO TABLE tx_stats FIELDS TERMINATED BY '\t' 
LINES TERMINATED BY '\n' 
(@var1,tx_source,tx_destination,tx_speed,tx_size,tx_destination_country_code2,tx_destination_country_name)
set logdate = STR_TO_DATE(@var1, '%M %d,%Y %h:%i:%s %p')


LOAD DATA LOCAL INFILE '/home/alogo/Downloads/rx_size.csv' 
INTO TABLE rx_stats FIELDS TERMINATED BY '\t' 
LINES TERMINATED BY '\n' 
(@var1,rx_source,rx_destination,rx_speed,rx_size,rx_destination_country_code2,rx_destination_country_name)
set logdate = STR_TO_DATE(@var1, '%M %d,%Y %h:%i:%s %p')


-------------------------Frequency dist--------------------------
SELECT ROUND(lobStats.tx_stats.tx_size, -6 )  / (1024*1024*1024)  AS bucket,
       COUNT(*)                    AS COUNT,
       RPAD('', LN(COUNT(*)), '*') AS bar
FROM   lobStats.tx_stats
GROUP  BY bucket;

----------------------------Update pref table-----------------------
INSERT INTO pref_table (ld_uid, storageSiteRef) SELECT uid, 3 AS prefblabla 
FROM (select 
  ld.uid
, pr.ld_uid
, pr.storageSiteRef
FROM ldata_table AS ld
LEFT JOIN pref_table AS pr ON pr.ld_uid = ld.uid
WHERE 1 = 1
AND ld.ownerid = 'mp1smw'
AND pr.ld_uid is null) AS a
;

---------------------Usare agents-------------------------------

sed -i 's/Jakarta\ Commons-HttpClient.*/Jakarta\ Commons-HttpClient/' req.csv
sed -i 's/cadaver.*/cadaver/' req.csv
sed -i 's/python-requests.*/python-requests/' req.csv
sed -i 's/Microsoft\ Data\ Access\ Internet\ Publishing\ Provider.*/Microsoft\ Data\ Access\ Internet\ Publishing\ Provider/' req.csv
sed -i 's/davfs2.*/davfs2/' req.csv
sed -i 's/Mozilla.*/Mozilla/' req.csv
sed -i 's/curl.*/curl/' req.csv
sed -i 's/Java.*/Java/' req.csv
sed -i 's/Cyberduck.*/Cyberduck/' req.csv
sed -i 's/gvfs.*/gvfs/' req.csv
sed -i 's/BitKinex.*/BitKinex/' req.csv
sed -i 's/Opera.*/Opera/' req.csv
sed -i 's/WebDAVLib.*/WebDAVLib/' req.csv
sed -i 's/WebDAVFS.*/WebDAVFS/' req.csv
sed -i 's/NetBox.*/NetBox/' req.csv
sed -i 's/Microsoft-WebDAV-MiniRedir.*/Microsoft-WebDAV-MiniRedir/' req.csv
sed -i 's/Apache-HttpClient.*/Apache-HttpClient/' req.csv
sed -i 's/Transmit.*/Transmit/' req.csv
sed -i 's/Benchmark.*/Benchmark/' req.csv
sed -i 's/UCI\ DAV\ Explorer.*/UCI\ DAV\ Explorer/' req.csv
sed -i 's/Wget.*/Wget/' req.csv
sed -i 's/Transmit.*/Transmit/' req.csv

----------------------------------------swift-----------------------------------------
swift --os-auth-url http://10.100.0.24:5000/v2.0/ --os-username username --os-password pass --os-tenant-name username list



-----------------------------Remove and clean storage site ---------------
UPDATE storage_site_table SET `removing` = true WHERE storageSiteId = ?;
UPDATE pdrigroup_table SET `needCheck` = true;



--------------------Deploy lobcder-master as dependency----------------------
mvn deploy:deploy-file -DgroupId=com.mycompany -DartifactId=lobcder-master-classes -Dversion=2.5 -Dpackaging=jar -Dfile="./lobcder/lobcder-master/target/lobcder-master-2.5-classes.jar" -Durl=file:..//mvn-repo/snapshots/

git add .
git commit -m "New"
git push origin master




-------------------------------- Manually replicate to new backend-------------------

-- CREATE TEMPORARY TABLE tmptable_1 SELECT * FROM pdri_table where storageSiteRef = 8;
-- ALTER TABLE tmptable_1 drop pdriId;
-- 
-- UPDATE tmptable_1 SET storageSiteRef = 9;
-- INSERT INTO pdri_table SELECT 0,tmptable_1.* FROM tmptable_1;
-- DROP TEMPORARY TABLE IF EXISTS tmptable_1;
